{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_names = pd.read_csv('fault_names.csv')\n",
    "#use overrideName, otherwise fullName if empty\n",
    "fault_names['name'] = fault_names['overrideName'].fillna(fault_names['fullName'])\n",
    "#remove if include=false\n",
    "fault_names = fault_names[fault_names['include'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centres = pd.read_csv('Driving Test Centres.csv')\n",
    "df_centres = df_centres.set_index('id')\n",
    "df_centres = df_centres.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore the first row. use second row as header\n",
    "df_annexc = pd.read_csv('Annex C.csv', skiprows=2, thousands=',')\n",
    "df_annexc = df_annexc.set_index('Test ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annexb = pd.read_csv('Annex B.csv', skiprows=2, thousands=',')\n",
    "#keep cols Test ID, SLOT_TIME, ATTEMPTS\n",
    "df_annexb = df_annexb[['Test ID', 'SLOT_TIME', 'ATTEMPTS']]\n",
    "df_annexb = df_annexb.set_index('Test ID')\n",
    "\n",
    "df_all = df_annexc.join(df_annexb, on='Test ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove comma from 'TC_ID' column values\n",
    "df_all['TC_ID'] = df_all['TC_ID'].astype(int)\n",
    "df_all['pass'] = df_all['TEST_RESULT'].apply(lambda x: 1 if x == 'P' else 0)\n",
    "df_all['SLOT_TIME'] = pd.to_datetime(df_all['SLOT_TIME'], format='%H:%M')\n",
    "df_all['TIME_BIN'] = df_all['SLOT_TIME'].dt.floor('60T')\n",
    "df_all['TIME_BIN_STR'] = df_all['TIME_BIN'].dt.strftime('%H:%M') + '-' + (df_all['TIME_BIN'] + pd.Timedelta('1H')).dt.strftime('%H:%M')\n",
    "df_all['PERIOD_DATE'] = pd.to_datetime(df_all['PERIOD_DATE'], format='%d/%m/%Y')\n",
    "df_all['DAY_OF_WEEK'] = df_all['PERIOD_DATE'].dt.day_name()\n",
    "df_all['DAY_TYPE'] = df_all['PERIOD_DATE'].apply(lambda x: 'Mon-Fri' if x.weekday() < 5 else 'Saturday' if x.weekday() == 5 else 'Sunday')\n",
    "df_all['ATTEMPTS_TRUNC'] = df_all['ATTEMPTS'].apply(lambda x: '5+' if x >= 5 else str(x))\n",
    "df_all['FIRST_ATTEMPT'] = df_all['ATTEMPTS'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any columns that end in _DANGER? Rename them to _DANGEROUS\n",
    "danger_columns = [col for col in df_all.columns if col.endswith('_DANGER')]\n",
    "for col in danger_columns:\n",
    "    df_all[col.replace('_DANGER', '_DANGEROUS')] = df_all[col]\n",
    "    df_all = df_all.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maneuvres = pd.read_csv('maneuvre_names.csv')\n",
    "#create dict of databaseField to shortName\n",
    "reverse_maneuvres = maneuvres[maneuvres['isReverseManeuvre'] == True].set_index('databaseField')['shortName'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_maneuvre_code(row):\n",
    "    for databaseField in reverse_maneuvres:\n",
    "        if row[databaseField] == 1:\n",
    "            return reverse_maneuvres[databaseField]\n",
    "    return 'Reversing maneuvre skipped'\n",
    "\n",
    "df_all['reverse_maneuvre'] = df_all.apply(get_maneuvre_code, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is possible though very rare for both a serious and dangerous fault to be recorded for the same test.\n",
    "# The dangerous/serious/total columns seem to be completely independent, although I thought minors should be disregarded if a serious or dangerous fault is present.\n",
    "# I will add suffix _FAILS to mean the max of both. _TOTAL actually means _MINOR\n",
    "for index, row in fault_names.iterrows():\n",
    "    #create fields if they don't exist\n",
    "    prefix = row['databaseFieldPrefix']\n",
    "    if prefix+ '_SERIOUS' not in df_all:\n",
    "        df_all[prefix + '_SERIOUS'] = 0\n",
    "    if prefix + '_DANGEROUS' not in df_all:\n",
    "        df_all[prefix + '_DANGEROUS'] = 0\n",
    "    if prefix + '_TOTAL' not in df_all:\n",
    "        df_all[prefix + '_TOTAL'] = 0\n",
    "    # serious or dangerous can only be 0 or 1. Take OR of both\n",
    "    df_all[prefix + '_FAILS'] = df_all[[prefix + '_SERIOUS', prefix + '_DANGEROUS']].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in maneuvres.iterrows():\n",
    "    man_code = row['databaseField']\n",
    "    fault_field_prefix = row['faultFieldPrefix']\n",
    "    cols = [col for col in df_all.columns if col.startswith(fault_field_prefix) and col.endswith('_FAILS')]\n",
    "    df_all[man_code + '_FAILS'] = df_all[cols].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangerous_faults_array = [f + '_DANGEROUS' for f in fault_names['databaseFieldPrefix']]\n",
    "serious_faults_array = [f + '_SERIOUS' for f in fault_names['databaseFieldPrefix']]\n",
    "minor_faults_array = [f + '_TOTAL' for f in fault_names['databaseFieldPrefix']]\n",
    "df_all['dangerous_count'] = df_all[dangerous_faults_array].sum(axis=1)\n",
    "df_all['serious_count'] = df_all[serious_faults_array].sum(axis=1)\n",
    "df_all['minor_count'] = df_all[minor_faults_array].sum(axis=1)\n",
    "df_all['dangerous_any'] = df_all[dangerous_faults_array].any(axis=1).astype(int)\n",
    "df_all['serious_any'] = df_all[serious_faults_array].any(axis=1).astype(int)\n",
    "df_all['minor_any'] = df_all[minor_faults_array].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aggregation(df_filtered, identifier):\n",
    "    df_avgs = df_filtered.mean(axis=0, numeric_only=True)\n",
    "    obj = {'minors': {}, 'fails': {}, 'maneuvres': []}\n",
    "    for index, row in fault_names.iterrows():\n",
    "        fault_name = row['name']\n",
    "        obj['minors'][fault_name] = df_avgs[row['databaseFieldPrefix'] + '_TOTAL']\n",
    "        obj['fails'][fault_name] = df_avgs[row['databaseFieldPrefix'] + '_FAILS']\n",
    "    obj['totalTestCount'] = len(df_filtered)\n",
    "    obj['dailyTestCount'] = obj['totalTestCount'] / 215\n",
    "    obj['pass'] = df_avgs['pass']\n",
    "    obj['dangerous_count'] = df_avgs['dangerous_count']\n",
    "    obj['serious_count'] = df_avgs['serious_count']\n",
    "    obj['minor_count'] = df_avgs['minor_count']\n",
    "    obj['dangerous_any'] = df_avgs['dangerous_any']\n",
    "    obj['serious_any'] = df_avgs['serious_any']\n",
    "    obj['minor_any'] = df_avgs['minor_any']\n",
    "    obj['first_attempt'] = df_avgs['FIRST_ATTEMPT']\n",
    "    obj['attempts'] = df_avgs['ATTEMPTS']\n",
    "\n",
    "\n",
    "    for code, man_name in maneuvres.set_index('databaseField')['shortName'].items():\n",
    "        df_filt_man = df_filtered[df_filtered[code] == 1]\n",
    "        pass_rate = df_filt_man.mean(axis=0, numeric_only=True)['pass']\n",
    "        pass_rate = 1.0 if pd.isna(pass_rate) else pass_rate\n",
    "        maneuvre_fails = df_filt_man.mean(axis=0, numeric_only=True)[code + '_FAILS']\n",
    "        maneuvre_fails = 0 if pd.isna(maneuvre_fails) else maneuvre_fails\n",
    "        obj['maneuvres'].append({'name': man_name, 'frequency': df_avgs[code], 'pass': pass_rate, 'maneuvre_fails': maneuvre_fails})\n",
    "\n",
    "\n",
    "    df_times = df_filtered.groupby(['DAY_TYPE', 'TIME_BIN_STR']).agg({'pass': 'mean', 'TC_ID': 'count'}).reset_index()\n",
    "    df_times['dailyTests'] = (df_times['TC_ID'] / 215) * 7\n",
    "    df_times['dailyTests'] = df_times.apply(lambda x: x['dailyTests'] / 5 if x['DAY_TYPE'] == 'Mon-Fri' else x['dailyTests'], axis=1)\n",
    "    df_times = df_times.rename(columns={'DAY_TYPE': 'dayType', 'TIME_BIN_STR': 'time'})\n",
    "    df_times = df_times.drop(columns=['TC_ID'])\n",
    "    obj['times'] = df_times.to_dict(orient='records')\n",
    "    df_days = df_filtered.groupby(['DAY_TYPE']).agg({'pass': 'mean', 'TC_ID': 'count'}).reset_index()\n",
    "    df_days['dailyTests'] = (df_days['TC_ID'] / 215) * 7\n",
    "    df_days['dailyTests'] = df_days.apply(lambda x: x['dailyTests'] / 5 if x['DAY_TYPE'] == 'Mon-Fri' else x['dailyTests'], axis=1)\n",
    "    df_days = df_days.rename(columns={'DAY_TYPE': 'dayType'})\n",
    "    df_days = df_days.drop(columns=['TC_ID'])\n",
    "    df_days['time'] = 'All times'\n",
    "    obj['times'] = obj['times'] + df_days.to_dict(orient='records')\n",
    "\n",
    "    obj['name'] = str(identifier)\n",
    "    if obj['name'].isnumeric():\n",
    "        obj['id'] = int(identifier)\n",
    "        if identifier in df_centres.index:\n",
    "            obj['address'] = df_centres.loc[identifier].to_dict()\n",
    "            obj['name'] = obj['address']['name']\n",
    "\n",
    "    with open('dtc_data/' + str(identifier) + '.json', 'w') as f:\n",
    "        json.dump(obj, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_aggregation(df_all, 'national')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for maneuvre in maneuvres['databaseField']:\n",
    "    process_aggregation(df_all[df_all[maneuvre] == 1], maneuvre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in df_all['TC_ID'].unique():\n",
    "    process_aggregation(df_all[df_all['TC_ID'] == id], id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dow in df_all['DAY_TYPE'].unique():\n",
    "    process_aggregation(df_all[df_all['DAY_TYPE'] == dow], dow)\n",
    "for time_bin in df_all['TIME_BIN_STR'].unique():\n",
    "    process_aggregation(df_all[df_all['TIME_BIN_STR'] == time_bin], time_bin.replace(':', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print tests that had serious_any but pass=1 YIELDS NONE\n",
    "\n",
    "\n",
    "# print tests by minor count - show pass rate and test count INTERESTING - SHOULD SHARE ON MISC PAGE\n",
    "df_all.groupby('minor_count').agg({'pass': ['mean', 'count']})\n",
    "\n",
    "# print tests by dangerous count - show pass rate and test count INTERESTING - SHOULD SHARE ON MISC PAGE\n",
    "df_all.groupby('serious_count').agg({'pass': ['mean', 'count']})\n",
    "\n",
    "\n",
    "unusual_fails = df_all[(df_all['serious_any'] == 0) & (df_all['dangerous_any'] == 0) & (df_all['minor_count'] <= 15) & (df_all['pass'] == 0)]\n",
    "if len(unusual_fails) > 0:\n",
    "    print('WARNING: There are unusual fails with no S+Ds')\n",
    "    print(unusual_fails.head())\n",
    "\n",
    "unusual_passes = df_all[((df_all['serious_any'] > 0) | (df_all['dangerous_any'] > 0) | (df_all['minor_count'] > 15)) & (df_all['pass'] == 1)]\n",
    "\n",
    "if len(unusual_passes) > 0:\n",
    "    print('WARNING: There are unusual passes, those passing despite S+Ds')\n",
    "    print(unusual_passes.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
